{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3587c25",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "a3587c25",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4bd9e05ff415d3e4b3e2039f86af13b7",
     "grade": false,
     "grade_id": "cell-945c2541e3bdcc8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Assignment 4. Denoising Diffusion Probabilistic Models (DDPM)\n",
    "\n",
    "The goal of this exercise is to get familiar with diffusion-based generative models using the DDPM model as an example. The model is proposed in [this paper](https://arxiv.org/pdf/2006.11239.pdf).\n",
    "\n",
    "**This exercise requires a significant amount of computing power, we recommend you to use a GPU if you have access to one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8191e7b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8191e7b3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c83583e2f815de5b73d3048b62e2444a",
     "grade": false,
     "grade_id": "cell-2afad36ca77820be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e80fc",
   "metadata": {
    "id": "9c4e80fc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d4f67",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7d4d4f67",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8306fc1764cffda16ae1151137725b78",
     "grade": true,
     "grade_id": "cell-6ab448c431e2040e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True\n",
    "\n",
    "import tools, warnings\n",
    "warnings.showwarning = tools.customwarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd60c6f",
   "metadata": {
    "id": "bdd60c6f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302151b9",
   "metadata": {
    "id": "302151b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50a071",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0b50a071",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d998f0bcbe98cf335ea02faf3d5c94d",
     "grade": false,
     "grade_id": "cell-c851c04eff89d9a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016061e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e016061e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14b6811299e105b1d6fcfbe28082de9f",
     "grade": false,
     "grade_id": "cell-c79631d312e26acf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Data\n",
    "\n",
    "In this exercise, we use standard MNIST data. To simplify the construction of the denoising model (U-net), we upscale the images to $32\\times 32$ resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25194dbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "25194dbf",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfdb41970bad8bf0af1fd181bc7445df",
     "grade": false,
     "grade_id": "cell-ec611ba9ba5acc48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3670ba4-9d4c-4110-aa01-c6d33a868b7a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b3670ba4-9d4c-4110-aa01-c6d33a868b7a",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39f54a6ff43f157bd6e9afb4d84b1c63",
     "grade": false,
     "grade_id": "cell-2686eef91c5ef389",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_images(images, ncol=12, figsize=(8,8), **kwargs):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axis('off')\n",
    "    out = rearrange(images, '(b1 b2) c h w -> c (b1 h) (b2 w)', b2=ncol).cpu()\n",
    "    if out.shape[0] == 1:\n",
    "        ax.matshow(out[0], **kwargs)\n",
    "    else:\n",
    "        ax.imshow(out.permute((1, 2, 0)), **kwargs)\n",
    "    display.display(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9ab5d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "78f9ab5d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "023d7e0507cf44cf5cdd54f717e56138",
     "grade": false,
     "grade_id": "cell-d831c320749ab9d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "e2a7eb28-7530-4c29-e47d-5353e01d2d4e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "print(images.shape)\n",
    "tools.show_images(images[:8], ncol=4, cmap='binary', clim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560de9c1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "560de9c1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6461919c5c24364bf42a1c011b06c5da",
     "grade": false,
     "grade_id": "cell-f5f8145f88340f22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Diffusion model (2 points)\n",
    "\n",
    "In DDPM, the forward process (or diffusion process) is a Markov chain that gradually adds Gaussian noise to the data according to a variance schedule $\\beta_1, ..., \\beta_T$:\n",
    "$$\n",
    "q(x_{1:T} | x_0) = \\prod^T_{t=1} q(x_t|x_{t−1}), \\quad q(x_t|x_{t−1}) = N (x_t; \\sqrt{1 − \\beta_t} x_{t−1}, \\beta_t I)\n",
    "$$\n",
    "\n",
    "* In our implementation of DDPM, we use a linear schedule for $\\beta_t$ that grows linearly from 0.0001 to 0.02 with T=1000 time steps in total. Please store the values of $\\beta_t$ in attribute `self.betas`.\n",
    "\n",
    "* We implement the forward diffusion process in function `forward()`. This function receives a clearn sample $x_0$ and a noise instance $\\epsilon_t$ and returns\n",
    "$$\n",
    "x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_t\n",
    "$$\n",
    "which is a sample from the following distribution:\n",
    "$$\n",
    "q(x_t|x_0) = N(x_t; \\sqrt{\\bar{\\alpha}_t} x_{0}, (1 - \\bar{\\alpha}_t) I)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\bar{\\alpha}_t = \\prod^t_{s=1} \\alpha_s\n",
    "\\qquad\n",
    "\\alpha_t = 1 − \\beta_t.\n",
    "$$\n",
    "Note that the denoising model is trained to predict the noise instance $\\epsilon_t$ which is why we create it outside of the function.\n",
    "\n",
    "* Samples are generated with an inverse diffusion process which we implement in function `sample()`. The sampling process is described in Algorithm 2 of the paper:\n",
    "<img src=\"alg_sampling.png\" width=350>\n",
    "where $\\sigma_t = \\sqrt{\\beta_t}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba55b4",
   "metadata": {
    "deletable": false,
    "id": "34ba55b4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b083f68599a68c5080615bad34b7f819",
     "grade": false,
     "grade_id": "cell-0a7364f703aa000f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Diffusion(nn.Module):\n",
    "    \"\"\"Diffusion model with a linear schedule of the temperatures.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_timesteps=1000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.inference_steps = torch.arange(self.num_timesteps-1, -1, -1)\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x, t, noise=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, ...): Input samples.\n",
    "          t of shape (batch_size,): Corruption temperatures.\n",
    "          noise of shape (batch_size, ...): Noise instanses used for corruption.\n",
    "          \n",
    "        Returns:\n",
    "          noisy sample of the same shape\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reverse_step(self, x, t, noise_pred):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, ...): Noisy samples at current corruption level: x_t.\n",
    "          t (int): Corruption timestep.\n",
    "          noise_pred of shape (batch_size, ...): Noise predicted by a denoising model.\n",
    "        \n",
    "        Returns:\n",
    "          prediction of x_{t - 1} of shape (batch_size, ...)\n",
    "        \"\"\"\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, x_shape, labels, init_x=None, return_sequence=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          model: A denoising model. model(x, t, labels) takes as inputs:\n",
    "                   x of shape (batch_size, n_channels, H, W): corrupted examples.\n",
    "                   t of shape (batch_size,): LongTensor of time steps.\n",
    "                   labels of shape (batch_size,): LongTensor of the classes of the examples in x.\n",
    "                 and outputs a denoised version of input x.\n",
    "          x_shape: The shape of the generated data. For example, to generate batch_size images of shape (1, H, W),\n",
    "                   x_shape should be (batch_size, 1, H, W).\n",
    "          labels of shape (batch_size,): LongTensor of the classes of generated samples.\n",
    "          init_x: Optional tensor of shape `x_shape`, providing the initial noisy input (x_T).\n",
    "                  If None, x_T is sampled from the gaussian prior.\n",
    "\n",
    "          return_sequence: If True, returns the entire denoising trajectory [x_T, ..., x_0].\n",
    "                           If False, only the final sample x_0 is returned.\n",
    "\n",
    "        Returns:\n",
    "            If return_sequence is False:\n",
    "                - A tensor of shape (batch_size, n_channels, H, W) containing the final samples.\n",
    "            If return_sequence is True:\n",
    "                - A tuple (x_0, trajectory), where trajectory is a list of tensors representing\n",
    "                  the intermediate states [x_T, ..., x_0].\n",
    "              \n",
    "        Note: Create new tensors on the same device where the model is.\n",
    "        \"\"\"\n",
    "        batch_size = x_shape[0]\n",
    "        assert labels is None or batch_size == len(labels), \"Sample batch size different from length of given labels\"\n",
    "\n",
    "        if init_x is None:\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            assert x_shape == init_x.shape, f\"Expected shape {x_shape}, but got {init_x.shape}\"\n",
    "            x = init_x\n",
    "\n",
    "        if return_sequence:\n",
    "            x_sequence = [x]\n",
    "\n",
    "        for t in self.inference_steps:\n",
    "            # compute noise prediction below\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "            x = self.reverse_step(x, t, noise_pred)\n",
    "            \n",
    "            if return_sequence:\n",
    "                x_sequence.append(x)\n",
    "\n",
    "        if not return_sequence:\n",
    "            return x\n",
    "        else:\n",
    "            return x, x_sequence\n",
    "\n",
    "\n",
    "def extract(a, t_batch, ndim):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      a: tensor of shape [T]\n",
    "      t_batch: tensor of shape [batch_size]\n",
    "      ndim (int)\n",
    "\n",
    "    Returns:\n",
    "      out of shape [batch_size, 1, ..., 1] where the number of 1s is equal to ndim-1.\n",
    "    \"\"\"\n",
    "    dims = (1,) * (ndim-1)\n",
    "    out = a[t_batch].view(-1, *dims)  # (batch_size, 1, 1, 1) to allow multiplication by x\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0775f8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5d0775f8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df34efba2732aa4521802322a4d730ba",
     "grade": true,
     "grade_id": "cell-7b30d34e460fa654",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "316744ef-09a9-4e93-c8d6-2132e0e4aeea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "diffusion = Diffusion(1000)\n",
    "assert diffusion.betas[0] == 1e-4, \"The lowest temperature should be 1e-4\"\n",
    "assert diffusion.betas[-1] == 0.02, \"The highest temperature should be 0.02\"\n",
    "assert len(diffusion.betas) == 1000, \"The number of steps should be 1000\"\n",
    "\n",
    "def test_diffusion_forward_shapes():\n",
    "    diffusion = Diffusion(1000)\n",
    "    batch_size = 2\n",
    "    x = torch.randn(batch_size, 1, 32, 32)\n",
    "    t = torch.LongTensor([500, 900])\n",
    "\n",
    "    out = diffusion.forward(x, t)\n",
    "    assert out.shape == x.shape, f\"Bad out.shape: {out.shape}\"\n",
    "\n",
    "    noise = torch.randn_like(x)\n",
    "    out = diffusion.forward(x, t, noise)\n",
    "    assert out.shape == x.shape, f\"Bad out.shape: {out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_diffusion_forward_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ccbf9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "052ccbf9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fd0ae0c6ed8aafebe4724c10c920871",
     "grade": true,
     "grade_id": "cell-5677c1c5306e5d59",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "8374e01a-70ef-4ac9-8eb6-840abe6b4f06",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_diffusion_forward():\n",
    "    diffusion = Diffusion(1000)\n",
    "    batch_size = 2\n",
    "    x = 2 * torch.ones(batch_size, 1, 32, 32)\n",
    "    t = torch.LongTensor([500, 900])\n",
    "    noise = torch.ones_like(x)\n",
    "    out = diffusion.forward(x, t, noise)\n",
    "    expected = torch.empty_like(x)\n",
    "    expected[0].fill_(1.51815533)\n",
    "    expected[1].fill_(1.03274309)\n",
    "\n",
    "    print('out:\\n', out)\n",
    "    print('expected correct:\\n', expected)\n",
    "    assert torch.allclose(expected, out), \"out does not match the expected value.\"\n",
    "    print('Success')\n",
    "\n",
    "out = test_diffusion_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5434aa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b5434aa6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "308a94f3185db93a3c80b37671a6f1f7",
     "grade": true,
     "grade_id": "cell-2d0f0f71bb7383eb",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "6e847030-70e2-41ba-875a-f8d65cb5e51e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DummyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, t, labels=None):\n",
    "        return x\n",
    "\n",
    "def test_diffusion_sample_shapes():\n",
    "    diffusion = Diffusion(1000).to(device)\n",
    "    batch_size = 2\n",
    "    x_shape = (batch_size, 1, 32, 32)\n",
    "    model = DummyModel()\n",
    "\n",
    "    \n",
    "    out = diffusion.sample(model, x_shape, labels=None)\n",
    "    assert out.shape == x_shape, f\"Bad out.shape: {out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_diffusion_sample_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07f001",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fe07f001",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84347e1df62ae250935ea8aea0d6898c",
     "grade": true,
     "grade_id": "cell-3b891e5b34a2569e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "d1fff9a6-047d-44c8-e360-eb2b96dc02e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unittest.mock\n",
    "\n",
    "def my_randn_like(x):\n",
    "    return torch.ones_like(x)\n",
    "\n",
    "def my_randn(*args, **kwargs):\n",
    "    return torch.ones(*args, **kwargs)\n",
    "\n",
    "def my_normal(mean, std, **kwargs):\n",
    "    return mean + std * torch.ones_like(std)\n",
    "\n",
    "@unittest.mock.patch('torch.randn_like', my_randn_like)\n",
    "@unittest.mock.patch('torch.randn', my_randn)\n",
    "@unittest.mock.patch('torch.normal', my_normal)\n",
    "def test_diffusion_sample():\n",
    "    diffusion = Diffusion(10)\n",
    "    model = DummyModel()\n",
    "    batch_size = 2\n",
    "    x_shape = (batch_size, 1, 32, 32)\n",
    "\n",
    "    out = diffusion.sample(model, x_shape, labels=None)\n",
    "    expected = torch.empty(x_shape).fill_(1.3058254)\n",
    "    print('out:\\n', out)\n",
    "    print('expected correct:\\n', expected)\n",
    "    assert torch.allclose(expected, out), \"out does not match the expected value.\"\n",
    "    print('Success')\n",
    "\n",
    "test_diffusion_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b2b3d0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c7b2b3d0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "524a927d0ff890b27e695d8747d4e239",
     "grade": false,
     "grade_id": "cell-2cb1575cb14a78c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can visualize the forward process in the cell below. Note that since `Diffusion.forward()` samples independent noise instances for different time steps $t$, the illustration below does **not** correspond to steps of the same diffusion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829f0e1",
   "metadata": {
    "id": "e829f0e1",
    "outputId": "998e92a5-4bec-4835-dcc9-a3c5b73798d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "diffusion = Diffusion(1000)\n",
    "t = torch.arange(0, diffusion.num_timesteps, 10)\n",
    "x, _ = random.choice(trainset)\n",
    "x = x[None, ...].tile(len(t), 1, 1, 1)  # (t_steps, c, h, w)\n",
    "\n",
    "x_perturbed = diffusion.forward(x, t)\n",
    "tools.show_images(x_perturbed, ncol=10, cmap='binary', clim=[-2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74f349",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cd74f349",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cea68298919655e1c6bd28a352b260cf",
     "grade": false,
     "grade_id": "cell-949e2d748ea3455a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Construct the denoising model (1 point)\n",
    "\n",
    "A denoising model is the model that predicts the noise instance $\\epsilon$\n",
    "$$\n",
    "  \\epsilon = f(\\tilde{x}, t, y)\n",
    "$$\n",
    "that was used to generate the corrupted sample $\\tilde{x}$ with the corruption level defined by time step $t$. For denoising conditioned on label $y$, the model additionally accepts the label information $y$.\n",
    "\n",
    "The output $\\epsilon$ of the model should have the same dimensionality as the input $\\tilde{x}$. The architecture that is very commonly used for $f$ is a U-net.\n",
    "\n",
    "The U-Net architecture is fixed, with all layers pre-defined in the `__init__()` method. Your task is to implement the forward pass.\n",
    "\n",
    "**Notes:** \n",
    "\n",
    "* The model uses blocks `ResidualBlock`, `Downsample` and `PositionalEmbedding` defined in `blocks.py`.\n",
    "* To enable conditioning on time step $t$, we encode the time step using an MLP.\n",
    "  \n",
    "* The encoder is a sequence of the following blocks:\n",
    "  * A convolutional layer with 3x3 kernel, `base_channels` output channels, which keeps the resolution of the input.\n",
    "  * `ResidualBlock` with `base_channels` output channels.\n",
    "  * `Downsample` layer which preserves the number of channels.\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `Downsample` layer which preserves the number of channels.\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `Downsample` layer which preserves the number of channels.\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "\n",
    "* The encoder is followed by a bottleneck layer which is\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  \n",
    "* The decoder is a sequence of the following blocks:\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `Upsample` layer which preserves the number of channels.\n",
    "\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `Upsample` layer which preserves the number of channels.\n",
    "\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `ResidualBlock` with `base_channels` output channels.\n",
    "  * `Upsample` layer which preserves the number of channels.\n",
    "\n",
    "  * `ResidualBlock` with `base_channels` output channels.\n",
    "  * `ResidualBlock` with `base_channels` output channels.\n",
    "  * A convolutional layer with 3x3 kernel, `img_channels` output channels, which keeps the resolution of the input.\n",
    "  \n",
    "\n",
    "* Each residual block receives the time-step embedding produced by the MLP defined above and the label of a sample as extra inputs.\n",
    "  \n",
    "* The inputs of the decoder residual blocks are concatenations of two signals: the output of the previous decoder layer and the skip signal produced by the corresponding layer of the encoder.\n",
    "\n",
    "* There are 8 skip signals in totals: they are the outputs of the first convolutional layer and the encoder blocks of type `ResidualBlock` and `Downsample`.\n",
    "\n",
    "* `Upsample` layers of the decoder do not receive skip signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86077142",
   "metadata": {
    "deletable": false,
    "id": "86077142",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "276d1e416727576e8943ac361aded3a7",
     "grade": false,
     "grade_id": "cell-7b96b0da7ae734ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from blocks import ResidualBlock, Downsample, Upsample, PositionalEmbedding\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"The denoising model.\n",
    "\n",
    "    Args:\n",
    "      img_channels (int): Number of image channels.\n",
    "      base_channels (int): Number of base channels.\n",
    "      time_emb_dim (int or None): The size of the embedding vector produced by the MLP which embeds the time input.\n",
    "      num_classes (int or None): Number of classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_channels, base_channels, time_emb_dim=None, num_classes=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            PositionalEmbedding(base_channels),\n",
    "            nn.Linear(base_channels, time_emb_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim),\n",
    "        ) if time_emb_dim is not None else None\n",
    "\n",
    "\n",
    "        # Encoder\n",
    "        self.init_conv = nn.Conv2d(img_channels, base_channels, 3, padding=1)\n",
    "\n",
    "        self.enc11 = ResidualBlock(base_channels, base_channels, time_emb_dim, num_classes)\n",
    "        self.down1 = Downsample(base_channels)\n",
    "        self.enc21 = ResidualBlock(base_channels, 2*base_channels, time_emb_dim, num_classes)\n",
    "        self.down2 = Downsample(2*base_channels)\n",
    "        self.enc31 = ResidualBlock(2*base_channels, 2*base_channels, time_emb_dim, num_classes)\n",
    "        self.down3 = Downsample(2*base_channels)\n",
    "        self.enc41 = ResidualBlock(2*base_channels, 2*base_channels, time_emb_dim, num_classes)\n",
    "\n",
    "        self.encoder_layers = [\n",
    "            self.enc11, self.down1,\n",
    "            self.enc21, self.down2,\n",
    "            self.enc31, self.down3,\n",
    "            self.enc41,\n",
    "        ]\n",
    "\n",
    "        self.mid1 = ResidualBlock(2*base_channels, 2*base_channels, time_emb_dim, num_classes)\n",
    "        \n",
    "        # Decoder\n",
    "        self.dec11 = ResidualBlock(2*base_channels*2, 2*base_channels, time_emb_dim, num_classes)\n",
    "        self.dec13 = ResidualBlock(2*base_channels*2, 2*base_channels, time_emb_dim, num_classes)\n",
    "        self.up1 = Upsample(2*base_channels)\n",
    "\n",
    "        self.dec21 = ResidualBlock(2*base_channels*2, 2*base_channels, time_emb_dim, num_classes)\n",
    "        self.dec23 = ResidualBlock(2*base_channels*2, 2*base_channels, time_emb_dim, num_classes)\n",
    "        self.up2 = Upsample(2*base_channels)\n",
    "\n",
    "        self.dec31 = ResidualBlock(2*base_channels*2, 2*base_channels, time_emb_dim, num_classes)\n",
    "        self.dec33 = ResidualBlock(2*base_channels + base_channels, base_channels, time_emb_dim, num_classes)\n",
    "        self.up3 = Upsample(base_channels)\n",
    "\n",
    "        self.dec41 = ResidualBlock(base_channels*2, base_channels, time_emb_dim, num_classes)\n",
    "        self.dec43 = ResidualBlock(base_channels*2, base_channels, time_emb_dim, num_classes)\n",
    "\n",
    "        self.decoder_layers = [\n",
    "            self.dec11, self.dec13, self.up1,\n",
    "            self.dec21, self.dec23, self.up2,\n",
    "            self.dec31, self.dec33, self.up3,\n",
    "            self.dec41, self.dec43,\n",
    "        ]\n",
    "\n",
    "        self.out_conv = nn.Conv2d(base_channels, img_channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x, time=None, labels=None):\n",
    "        \"\"\"Estimate noise instances used to produced corrupted examples `x` with the corruption level determined\n",
    "        by `time`. `labels` contains the class information of the examples in `x`.\n",
    "\n",
    "        Args:\n",
    "          x of shape (batch_size, n_channels, H, W): Corrupted examples.\n",
    "          time of shape (batch_size,): LongTensor of time steps which determine the corruption level for\n",
    "                                       the examples in x.\n",
    "          labels of shape (batch_size,): LongTensor of the classes of the examples in x.\n",
    "\n",
    "        Returns:\n",
    "          out of shape (batch_size, n_channels, H, W)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88e2e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dd88e2e7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "006de4df7042bbc89f50cd8c61838451",
     "grade": true,
     "grade_id": "cell-2c65621a090d29df",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "047b5b33-90ee-469c-ab0c-ecc5561b6e7e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_Unet_forward():\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed(0)\n",
    "    unet = UNet(\n",
    "        img_channels=1,\n",
    "        base_channels=128,\n",
    "        time_emb_dim=32,\n",
    "        num_classes=11,\n",
    "    )\n",
    "    unet.eval()\n",
    "    \n",
    "    batch_size = 2\n",
    "    x = torch.ones(batch_size, 1, 32, 32)\n",
    "    t = torch.LongTensor([900, 900])\n",
    "    labels = torch.LongTensor([0, 1])\n",
    "    out = unet(x, t, labels)\n",
    "    correct_out = torch.load('test_unet_output.pth', map_location=lambda storage, loc: storage)\n",
    "    \n",
    "    assert out.shape == x.shape, f\"Bad out.shape: {out.shape}\"\n",
    "    assert torch.allclose(out, correct_out), \"out does not match the expected value.\"\n",
    "    print('Success')\n",
    "    \n",
    "\n",
    "test_Unet_forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3213e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "90f3213e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e0967922b7479bd49f511a13a3eec59",
     "grade": false,
     "grade_id": "cell-e58c21f485ea4af1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Train the model (3 points)\n",
    "\n",
    "Implement the training loop in the cell below.\n",
    "\n",
    "The training procedure consists of the following steps for each mini-batch:\n",
    "* Sample uniformly time steps from 0 to `Diffusion.num_timesteps-1` for each training example.\n",
    "* Compute corrupted samples with `Diffusion.forward`.\n",
    "* Estimate the noise used to generate the corrupted samples with the U-net model.\n",
    "* The loss is the MSE loss between the estimated noise and the ground-truth noise.\n",
    "\n",
    "The implementation should follow Algorithm 1 of the paper:\n",
    "<img src=\"alg_training.png\" width=350>\n",
    "\n",
    "**The recommended hyperparameters:**\n",
    "* Adam optimizer with learning rate 0.001\n",
    "* Number of epochs: 15. On a CPU, each epoch takes approximately 10 minutes. Training for 5 epochs is typically sufficient to pass the tests.\n",
    "\n",
    "**Conditional + Unconditional training:**\n",
    "- You will train the model to handle both conditional and unconditional generation:\n",
    "- The dataset includes $10$ digit classes, so we set ```num_classes = 11``` by adding one dummy class for unconditional training.\n",
    "- During training, randomly replace 10% of the class labels with the dummy label. This allows the model to learn unconditional noise prediction.\n",
    "\n",
    "**Hints:**\n",
    "- The loss at convergence should reach 0.017 after about 11 epochs. We check that the loss is below 0.02 in the grading tests.\n",
    "- You can track the training progress by plotting 120 generated samples and computing the FD score using the code below\n",
    "```python\n",
    "fdscore = fd.FDScore.pretrained(imsize=32)\n",
    "fdscore.to(device)\n",
    "...\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    x_shape = (120, 1, 32, 32)\n",
    "    labels = torch.cat([torch.arange(10) for _ in range(12)], dim=0).to(device)\n",
    "    samples = diffusion.sample(model, x_shape, labels)\n",
    "    score = fdscore.calculate(samples)\n",
    "\n",
    "    samples = ((samples + 1) / 2).clip(0, 1)\n",
    "    tools.show_images(samples, cmap='binary', ncol=10)\n",
    "\n",
    "    print(f'FD score: {score:.5f}')\n",
    "```\n",
    "- The FD score for a conditional model should be below 0.6 at convergence. We check that it is below 1 in the grading tests.\n",
    "- **Do not forget to set the model into the training mode by `net.train()` before training.**\n",
    "- The generated samples are expected to look similar to this:\n",
    "<img src=\"diffusion_samples.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d61342",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "08d61342",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8e93465d274b62c6cb43c82d5610127",
     "grade": false,
     "grade_id": "cell-2ce48e9667bfa679",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a model\n",
    "diffusion = Diffusion(1000)\n",
    "model = UNet(\n",
    "    img_channels=1,\n",
    "    base_channels=32,\n",
    "    time_emb_dim=32,\n",
    "    num_classes=10 + 1,\n",
    ")\n",
    "diffusion.to(device);\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3931ee-f6ad-49dd-b928-fe93663b3931",
   "metadata": {
    "deletable": false,
    "id": "4b3931ee-f6ad-49dd-b928-fe93663b3931",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "662642a386e9511dd53c8ae107f0a70c",
     "grade": false,
     "grade_id": "cell-8978b6575b796131",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "693140f4-a21e-4583-a532-43320b69d624",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c514b",
   "metadata": {
    "id": "c98c514b",
    "outputId": "e615e3c4-82c6-41d0-92e8-0a7f854a2f4c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "# Set confirm=False if you do not want to be asked for confirmation before saving.\n",
    "if not skip_training:\n",
    "    tools.save_model(diffusion, '1_diffusion.pth', confirm=True)\n",
    "    tools.save_model(model, '1_unet.pth', confirm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b186fc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c9b186fc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fea7a3d584f221419b44a279b9ff4a54",
     "grade": false,
     "grade_id": "cell-6e4868563ae0df3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    diffusion = Diffusion(1000)\n",
    "    model = UNet(\n",
    "        img_channels=1,\n",
    "        base_channels=32,\n",
    "        time_emb_dim=32,\n",
    "        num_classes=10 + 1,\n",
    "    )\n",
    "\n",
    "    tools.load_model(diffusion, '1_diffusion.pth', device)\n",
    "    tools.load_model(model, '1_unet.pth', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136da2e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "136da2e1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f99f3d1538640b4023a8ef1111a2290",
     "grade": false,
     "grade_id": "cell-f2ac7d8e180308fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2704377c-f033-437b-83e4-758bc90a8a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222071e-96f0-4147-9fc9-2ff0561fe66c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "f222071e-96f0-4147-9fc9-2ff0561fe66c",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ec7d269d89ea3ba32599b0050ac22e2",
     "grade": false,
     "grade_id": "cell-47524f693586d7ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save generated samples (the pth-files will be submitted automatically together with your notebook)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "    \n",
    "if not skip_training:\n",
    "    with torch.no_grad():\n",
    "        x_shape = (120, 1, 32, 32)\n",
    "        init_x = torch.randn(*x_shape, device=device)\n",
    "        labels = torch.cat([torch.arange(10) for _ in range(12)], dim=0).to(device)\n",
    "        \n",
    "        samples = diffusion.sample(model, x_shape, labels, init_x=init_x)\n",
    "        torch.save(samples, '1_samples.pth')\n",
    "else:\n",
    "    samples = torch.load('1_samples.pth', map_location=lambda storage, loc: storage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658951e-4ca6-46ac-8df9-62b0caf06e04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d658951e-4ca6-46ac-8df9-62b0caf06e04",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aedc502c676d042c35b4827aa62436b4",
     "grade": true,
     "grade_id": "cell-9b2c8f04e9206fa2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "436ec90f-4698-4e7e-e1dd-1da1d2daa0b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdscore = fd.FDScore.pretrained(imsize=32)\n",
    "fdscore.to(device)\n",
    "score = fdscore.calculate(samples)\n",
    "print('FD score:', score)\n",
    "assert score < 1, 'The FD score should be below 1'\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea4ac51",
   "metadata": {
    "id": "6ea4ac51",
    "outputId": "0a4b0ca5-6ee7-41a0-e43d-561bf364aec5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples01 = ((samples + 1) / 2).clip(0, 1)\n",
    "tools.show_images(samples01, cmap='binary', ncol=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f75cb4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e3f75cb4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4503a3d4d48dad538f1582b9a7c2707e",
     "grade": true,
     "grade_id": "cell-ba1728626cc1c211",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "051b7681-ae64-4a71-9b34-14c6ca19c38a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell tests the training loss of the trained denoising model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8467d9-6e84-43a5-b058-8cf0b9ee6aea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1f8467d9-6e84-43a5-b058-8cf0b9ee6aea",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d962d4e468cf0115ce5c253b03630ae",
     "grade": false,
     "grade_id": "cell-b8ed457ea5325171",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Classifier free guidance (1 point)\n",
    "\n",
    "In this exercise, your objective is to **improve sample quality** by implementing **classifier-free guidance**. This method was introduced in [this paper](https://arxiv.org/abs/2207.12598).\n",
    "\n",
    "#### Core Idea\n",
    "\n",
    "Consider a conditional diffusion model that estimates $p(x \\mid c)$, where $x$ is a sample (an image) and $c$ is a condition (a label).\n",
    "\n",
    "Using Bayes' theorem, we can express the *implicit classifier* $p(c \\mid x)$ as:\n",
    "\n",
    "$$\n",
    "\\log p(c \\mid x) = \\log p(x \\mid c) + \\log p(c) - \\log p(x).\n",
    "$$\n",
    "\n",
    "Note that  $p(x)$ is the unconditional model, which we approximate as $p(x \\mid c = \\emptyset)$. This insight allows us to guide the sampling process without needing an external classifier.\n",
    "\n",
    "#### Guidance Formula\n",
    "\n",
    "To apply this idea during sampling, we adjust the score as in classifier guidance:\n",
    "\n",
    "$$\n",
    "\\nabla_x \\left[\\log p(x \\mid c) + \\omega \\log p(c \\mid x)\\right]\n",
    "$$\n",
    "\n",
    "Substituting the expression for $\\log p(c \\mid x)$, we get:\n",
    "\n",
    "$$\\nabla_x[\\log p(x | c) + \\omega \\log p(c | x)] = \\nabla_x[\\log p(x | c) + \\omega (\\log p(x| c) + \\log p(c) - \\log p(x))] = \\nabla_x[\\log p(x | c) (1 + \\omega) - \\omega \\log p(x)].$$\n",
    "\n",
    "\n",
    "Here, $\\omega$ is a **guidance scale** that controls how strongly the conditioning influences the generation. Larger values of $\\omega$ typically produce more faithful but potentially less diverse samples.\n",
    "\n",
    "#### Reparametrization\n",
    "\n",
    "In the denoising process, instead of directly modeling probabilities, we predict the noise $\\epsilon_\\theta$. Applying classifier-free guidance leads to the adjusted noise prediction:\n",
    "\n",
    "$$\n",
    "\\tilde{\\epsilon}_\\theta(x | c) = (1 + \\omega) \\, \\epsilon_\\theta(x| c) - \\omega \\, \\epsilon_\\theta(x)\n",
    "$$\n",
    "\n",
    "- $ \\epsilon_\\theta(x| c) $: noise predicted *with* the condition.\n",
    "- $ \\epsilon_\\theta(x) $: noise predicted *without* the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11009cf9-aab9-49fb-8b49-52b2e75fd4e6",
   "metadata": {
    "deletable": false,
    "id": "11009cf9-aab9-49fb-8b49-52b2e75fd4e6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02e78cc9b238ff33d118cf016f18facc",
     "grade": false,
     "grade_id": "cell-7a50733cad29f030",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_with_guidance(diffusion, model, x_shape, labels, init_x=None, return_sequence=False, guidance_scale=2.):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      diffusion: A diffusion model.\n",
    "      model: A denoising model.\n",
    "      x_shape: The shape of the generated data.\n",
    "      labels of shape (batch_size,): LongTensor of the classes of generated samples.\n",
    "      init_x: Optional tensor of shape `x_shape`, providing the initial noisy input (x_T).\n",
    "              If None, x_T is sampled from the gaussian prior.\n",
    "\n",
    "      return_sequence: If True, returns the entire denoising trajectory [x_T, ..., x_0].\n",
    "                       If False, only the final sample x_0 is returned.\n",
    "      guidance_scale: Parameter omega in the classifier-free guidance formula.\n",
    "\n",
    "    Returns:\n",
    "        If return_sequence is False:\n",
    "            - A tensor of shape (batch_size, n_channels, H, W) containing the final samples.\n",
    "        If return_sequence is True:\n",
    "            - A tuple (x_0, trajectory), where trajectory is a list of tensors representing\n",
    "              the intermediate states [x_T, ..., x_0].\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size = x_shape[0]\n",
    "        assert labels is None or batch_size == len(labels), \"Sample batch size different from length of given labels\"\n",
    "\n",
    "        if init_x is None:\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            assert x_shape == init_x.shape, f\"Expected shape {x_shape}, but got {init_x.shape}\"\n",
    "            x = init_x\n",
    "\n",
    "        if return_sequence:\n",
    "            x_sequence = [x]\n",
    "\n",
    "        for t in diffusion.inference_steps:\n",
    "            # compute noise prediction below\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "            x = diffusion.reverse_step(x, t, noise_pred)\n",
    "\n",
    "            if return_sequence:\n",
    "                x_sequence.append(x)\n",
    "\n",
    "        if not return_sequence:\n",
    "            return x\n",
    "        else:\n",
    "            return x, x_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae8a78-8896-427d-9a1c-41ebfa2e9a4d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "64ae8a78-8896-427d-9a1c-41ebfa2e9a4d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5138f70112c0d38b16021911a6de67d",
     "grade": false,
     "grade_id": "cell-0a09e4e4b343f5f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save generated samples (the pth-files will be submitted automatically together with your notebook)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "\n",
    "if not skip_training:\n",
    "    with torch.no_grad():\n",
    "        x_shape = (120, 1, 32, 32)\n",
    "        init_x = torch.randn(*x_shape, device=device)\n",
    "        labels = torch.cat([torch.arange(10) for _ in range(12)], dim=0).to(device)\n",
    "        \n",
    "        samples = sample_with_guidance(diffusion, model, x_shape, labels=labels, init_x=init_x, guidance_scale=1.)\n",
    "        torch.save(samples, '2_samples.pth')\n",
    "else:\n",
    "    samples = torch.load('2_samples.pth', map_location=lambda storage, loc: storage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeebf32-8cc8-483c-b82a-c54e9af42aa3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "adeebf32-8cc8-483c-b82a-c54e9af42aa3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52f138ab210ac692690cbd020ed42bdf",
     "grade": true,
     "grade_id": "cell-89c8843162d10f3d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "23bc8303-2b3a-4d0d-c4e0-f81b28c43ff9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdscore = fd.FDScore.pretrained(imsize=32)\n",
    "fdscore.to(device)\n",
    "score = fdscore.calculate(samples)\n",
    "\n",
    "baseline_samples = torch.load('1_samples.pth', map_location=lambda storage, loc: storage)\n",
    "fd_score_baseline = fdscore.calculate(baseline_samples)\n",
    "\n",
    "print('FD score:', score)\n",
    "assert score < max(0.5, fd_score_baseline), 'The FD score should be below 0.5 or lower than the baseline'\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb80af-d805-422c-8e6e-264d1ec3ab76",
   "metadata": {
    "id": "01bb80af-d805-422c-8e6e-264d1ec3ab76",
    "outputId": "d1ed21c0-cd92-4602-9463-ca2e818d928e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples01 = ((samples + 1) / 2).clip(0, 1)\n",
    "tools.show_images(samples01, cmap='binary', ncol=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55965165-a2ad-4c06-af0d-8a0b1b8f36b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "55965165-a2ad-4c06-af0d-8a0b1b8f36b0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "721e52f4b9f60c4a4665e6ce7da51650",
     "grade": false,
     "grade_id": "cell-975286b13de65ea9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Accelerated sampling (3 points)\n",
    "\n",
    "Diffusion models are highly effective at generating high-quality images. However, they tend to be significantly slower during inference than other generative models, primarily due to their sequential sampling process, which requires many iterative steps.\n",
    "\n",
    "In this exercise, you will explore a technique that greatly accelerates inference without sacrificing sample quality. You will also gain the ability to perform deterministic sampling, which can be especially useful in applications where reproducibility or fine control is important.\n",
    "\n",
    "Let us review the theoretical foundation behind this method.\n",
    "### Denoising diffusion implicit model\n",
    "\n",
    "Denoising diffusion implicit model was introduced in [this paper](). It proposes to use a non-Markovian inference distribution that induces the same marginals as DDPM. In particular, let the inference process be factorized as\n",
    "$$\n",
    "q_{\\sigma, \\tau}(x_{1:T} | x_0) = q_{\\sigma, \\tau}(x_{\\tau_S} | x_0) \\prod_{i = 1}^{S} q_{\\sigma, \\tau}(x_{\\tau_{i - 1}} | x_{\\tau_{i}},  x_0) \\prod_{t \\in \\bar\\tau} q_{\\sigma, \\tau}(x_t | x_0),\n",
    "$$\n",
    "where $\\tau$ is a subsequence of $[0, \\dots, T]$ of length $S$ with $\\tau_S = T$, and $\\bar \\tau$ is defined as its complement $\\bar\\tau = [0, \\dots, T] \\setminus \\tau $. Define:\n",
    "$$\n",
    "q_{\\sigma, \\tau}(x_{\\tau_{i - 1}} | x_{\\tau_{i}},  x_0) = \\mathcal N\\left(\\sqrt{\\bar\\alpha_{\\tau_{i - 1}}} x_0 + \\sqrt{1 - \\bar\\alpha_{\\tau_{i - 1}} - \\sigma^2_{\\tau_i}} \\dfrac{x_{\\tau_i} - \\sqrt{\\bar\\alpha_{\\tau_{i}}} x_0}{\\sqrt{1 - \\bar\\alpha_{\\tau_{i}}}}, \\sigma^2_{\\tau_i}I\\right) \\quad \\forall i \\in [1, \\dots, S]\n",
    "$$\n",
    "and\n",
    "$$\n",
    "q_{\\sigma, \\tau}(x_t | x_0) = \\mathcal N\\left(\\sqrt{\\bar\\alpha_{t}} x_0, (1 - \\bar\\alpha_t) I \\right) \\quad \\forall t \\in \\bar\\tau \\cup \\{T\\}.\n",
    "$$\n",
    "\n",
    "The coefficients are chosen to ensure that the marginals of DDPM and DDIM match:\n",
    "$$q_{\\sigma, \\tau}(x_{\\tau_{i}} | x_0) = q(x_{\\tau_{i}} | x_0).$$\n",
    "\n",
    "\n",
    "The corresponding generative process is modeled by\n",
    "$$\n",
    "p_{\\theta}(x_{0:T}) := p_{\\theta}(x_T)\n",
    "\\underbrace{\\prod_{i=1}^{S} p_{\\theta}^{(\\tau_i)}(x_{\\tau_{i-1}} | x_{\\tau_i})}_{\\text{use to produce samples}} \n",
    "\\times\n",
    "\\underbrace{\\prod_{t \\in \\bar\\tau} p_{\\theta}^{(t)}(x_0 | x_t)}_{\\text{in variational objective}},\n",
    "$$\n",
    "where only part of the models are being used to produce samples.\n",
    "\n",
    "The conditionals are given by\n",
    "$$\n",
    "    p_{\\theta}^{(\\tau_i)}(x_{\\tau_{i-1}} | x_{\\tau_i}) = q_{\\sigma,\\tau}(x_{\\tau_{i-1}} | x_{\\tau_i}, f_{\\theta}^{(\\tau_i)}(x_{\\tau_i})) \\quad \\text{if } i \\in [S], i > 1\n",
    "$$\n",
    "and\n",
    "$$\n",
    "    p_{\\theta}^{(t)}(x_0 | x_t) = \\mathcal{N}(f_{\\theta}^{(t)}(x_t), \\sigma_t^2 I),\n",
    "$$\n",
    "where $$f_{\\theta}^{(t)}(x_t) := \\frac{x_t - \\sqrt{1 - \\bar\\alpha_t} \\cdot \\epsilon_{\\theta}(x_t, t)}{\\sqrt{\\bar\\alpha_t}}.$$\n",
    "\n",
    "It can be shown that the variational objective is equivalent (up to a constant) to the DDPM objective, and thus, no retraining is needed.\n",
    "\n",
    "To sample from DDIM, we generate a sample $x_{\\tau_{i -1}}$ from a sample $x_{\\tau_i}$ via:\n",
    "$$\n",
    "x_{\\tau_{i - 1}} = \\sqrt{\\bar\\alpha_{\\tau_{i - 1}}} \\left(\\dfrac{x_{\\tau_i} - \\sqrt{1 - \\bar\\alpha_{\\tau_{i}}} \\epsilon_{\\theta}(x_{\\tau_i}, \\tau_{i})}{\\sqrt{\\bar\\alpha_{\\tau_{i}}}} \\right) + \\sqrt{1 - \\bar\\alpha_{\\tau_{i - 1}} - \\sigma_{\\tau_i}^2} \\epsilon_{\\theta}(x_{\\tau_i}, \\tau_{i}) + \\sigma_{\\tau_i} \\epsilon_{\\tau_{i}}, \\quad \\epsilon_{\\tau_{i}} \\sim \\mathcal N(0, I)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a91b3a6c99e7ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "a5a91b3a6c99e7ad",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b41b97d991e9b93671dd205dec95b5cf",
     "grade": false,
     "grade_id": "cell-9d39993ed03de856",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "### Theoretical task\n",
    "\n",
    "In this exercise, you will show that **DDPM is a special case** of DDIM by selecting a specific time schedule and noise parameter.\n",
    "\n",
    "Specifically, prove that when:\n",
    "- The time schedule is the full sequence:  \n",
    "  $$\n",
    "  \\tau = [0, 1, \\dots, T]\n",
    "  $$\n",
    "- And the noise parameter is set to:  \n",
    "  $$\n",
    "  \\sigma_t = \\sqrt{\\frac{1 - \\bar\\alpha_{t - 1}}{1 - \\bar\\alpha_{t}}} \\cdot \\sqrt{1 - \\frac{\\bar\\alpha_{t}}{\\bar\\alpha_{t - 1}}}\n",
    "  $$\n",
    "\n",
    "then the DDIM inference and generative processes **reduces to** the DDPM inference and generative processes.\n",
    "\n",
    "Write your solutions in LateX or attach a picture in the answer cell provided below. You can add a picture using the command ```![1](imagename_in_the_folder.jpg)```. Latex in hereWrite your solutions in LateX or attach a picture in the answer cell provided below. You can add a picture using the command ```![1](imagename_in_the_folder.jpg)```. Latex in here works similarly as you would write it normally!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99707768-ca1d-485c-b2d7-a98faaa4d575",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c48e5848e749e724566cc43186bab9d7",
     "grade": true,
     "grade_id": "cell-ddaa06f56c79ee32",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b20438dcfe46e25",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5b20438dcfe46e25",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9048e9e61e2b2540cd160f4f1f2be129",
     "grade": false,
     "grade_id": "cell-c7a4215051290f55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Implement DDIM\n",
    "\n",
    "Implement DDIM by changing the reverse_step method of the diffusion model. Use the following schedule for $\\sigma$:\n",
    "$$\\sigma_t = \\eta \\sqrt{\\frac{1 - \\bar\\alpha_{\\tau_{i - 1}}}{1 - \\bar\\alpha_{\\tau_{i}}}} \\sqrt{1 - \\frac{\\bar\\alpha_{\\tau_{i}} }{\\bar\\alpha_{\\tau_{i - 1}}}},$$\n",
    "where $\\eta \\in [0, 1]$ is a hyperparameter. When $\\eta = 1$ we recover DDPM, while $\\eta = 0$ corresponds to the deterministic sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f517e5-08f7-4a6d-b02e-706631d632d9",
   "metadata": {
    "deletable": false,
    "id": "30f517e5-08f7-4a6d-b02e-706631d632d9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2196254df3bc3f66f586af329967e09",
     "grade": false,
     "grade_id": "cell-853d80328aff6eaa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DDIM(Diffusion):\n",
    "    \"\"\"Denoising Diffusion Implicit Model\n",
    "    \"\"\"\n",
    "    def __init__(self, num_timesteps=1000, num_inference_steps=50, eta=1.):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          num_timesteps: Total number of diffusion steps used in training (1000).\n",
    "          num_inference_steps: Number of steps to use during sampling.\n",
    "          eta: Parameter controling the stochasticity of the sampler. \n",
    "        \"\"\"\n",
    "        super().__init__(num_timesteps)\n",
    "        inference_steps = np.linspace(0, num_timesteps - 1, num_inference_steps).round()[::-1].astype(np.int64)\n",
    "        self.inference_steps = torch.from_numpy(inference_steps)\n",
    "        self.eta = eta\n",
    "\n",
    "        # you can define other attributes below\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reverse_step(self, x, t, noise_pred):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, ...): Noisy samples at current corruption level: x_t.\n",
    "          t (int): Corruption timestep.\n",
    "          noise_pred of shape (batch_size, ...): Noise predicted by a denoising model.\n",
    "        \n",
    "        Returns:\n",
    "          prediction of x_{t - 1} of shape (batch_size, ...)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34969991-e411-40c4-9663-1702f223d7fd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "34969991-e411-40c4-9663-1702f223d7fd",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0bfddb62a9dc99381a726619e9c2bcc5",
     "grade": true,
     "grade_id": "cell-e9697b189877ff6e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddim_diffusion = DDIM(1000, num_inference_steps=50, eta=1.)\n",
    "ddim_diffusion.to(device);\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_shape = (120, 1, 32, 32)\n",
    "    labels = torch.cat([torch.arange(10) for _ in range(12)], dim=0).to(device)\n",
    "    samples = ddim_diffusion.sample(model, x_shape, labels)\n",
    "    \n",
    "fdscore = fd.FDScore.pretrained(imsize=32)\n",
    "fdscore.to(device)\n",
    "score = fdscore.calculate(samples)\n",
    "print('FD score:', score)\n",
    "assert score < 1, 'The FD score should be below 1'\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35af304-6a98-49c6-9574-ee01ded2756b",
   "metadata": {
    "id": "e35af304-6a98-49c6-9574-ee01ded2756b",
    "outputId": "d638e92e-0d8b-4e43-f71e-f3e109d1d3f8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples01 = ((samples + 1) / 2).clip(0, 1)\n",
    "tools.show_images(samples01, cmap='binary', ncol=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe460e1-6837-42ca-8f64-18774e252691",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "efe460e1-6837-42ca-8f64-18774e252691",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fadde2c8929e32eec73517ee0bccb57",
     "grade": false,
     "grade_id": "cell-2b052cd9107a7ff0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deterministic_diffusion = DDIM(1000, num_inference_steps=1000, eta=0)\n",
    "deterministic_diffusion.to(device);\n",
    "    \n",
    "if not skip_training:\n",
    "    with torch.no_grad():\n",
    "        x_shape = (20, 1, 32, 32)\n",
    "        labels = torch.cat([torch.arange(10) for _ in range(2)], dim=0).to(device)\n",
    "        init_x = torch.randn(((10, 1, 32, 32))).repeat(2, 1, 1, 1).to(device)\n",
    "        samples = deterministic_diffusion.sample(model, x_shape, labels, init_x=init_x)\n",
    "        torch.save(samples, '3_samples.pth')\n",
    "else:\n",
    "    samples = torch.load('3_samples.pth', map_location=lambda storage, loc: storage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174487de-a7f9-43df-80fc-19d063d50cad",
   "metadata": {
    "id": "174487de-a7f9-43df-80fc-19d063d50cad",
    "outputId": "f7ca4289-47d8-4882-e674-6e9143371893",
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples01 = ((samples + 1) / 2).clip(0, 1)\n",
    "tools.show_images(samples01, cmap='binary', ncol=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8d2e2-e94d-45be-8c3b-0034ff48dcd6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2df8d2e2-e94d-45be-8c3b-0034ff48dcd6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1e538900a4054884b23a114fdc0f9c8",
     "grade": true,
     "grade_id": "cell-e49ec7d73f464662",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "d120a804-0b4f-4b44-b931-7107f1419359",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_DDIM():\n",
    "    deterministic_diffusion = DDIM(1000, num_inference_steps=1000, eta=0)\n",
    "    deterministic_diffusion.to(device);\n",
    "    \n",
    "    x = torch.ones(2, 1, 32, 32)\n",
    "    t = torch.LongTensor([999])\n",
    "    y = torch.zeros(2, 1, 32, 32)\n",
    "    \n",
    "    out = deterministic_diffusion.reverse_step(x, t, y)\n",
    "    expected = torch.empty(x.shape).fill_(1.0101524591445923)\n",
    "    assert torch.allclose(expected, out), \"out does not match the expected value.\"\n",
    "    \n",
    "    out = deterministic_diffusion.reverse_step(y, t, x)\n",
    "    expected = torch.empty(x.shape).fill_(-0.010152757167816162)\n",
    "    assert torch.allclose(expected, out), \"out does not match the expected value.\"\n",
    "    print('Success')\n",
    "    \n",
    "\n",
    "assert torch.allclose(*samples.chunk(2), atol=1e-5), 'Two rows should be identical'    \n",
    "test_DDIM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75678d52-1e10-45fd-90f8-c9b68f3c63d6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb164ab58c727e32ea3a2abfc0452183",
     "grade": false,
     "grade_id": "cell-b3b0e5652e1d03e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Suggestion:** To ensure that exercises can be completed independently, we have not tested DDIM sampling in combination with classifier-free guidance. However, these two techniques are complementary, and you are encouraged to experiment with using both together to potentially improve sampling speed and image quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fdbc69",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "66fdbc69",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7b74c534ecd8c64c1329903bae02bad",
     "grade": false,
     "grade_id": "cell-77a89d4ae55de964",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## In-painting: Conditional generation given known parts of a generated image (2 points)\n",
    "\n",
    "One of the benefits of diffusion-based generative model is the possibility to use a trained model for *conditional* generation of some parts (of an image) given known values of other parts. For example, given the top part of an image (like in the images shown below) the model can generate samples which have the given values in the top part:\n",
    "\n",
    "<img src=\"conditioning.png\" width=400> <img src=\"cond_samples.png\" width=400>\n",
    "\n",
    "In the cell below, your need to implement a function that generate samples conditioned on known parts of samples using your trained diffusion model. Optionally, you can add classifier free guidance or DDIM sampling to accelerate sampling and increase image quality. Tests will only evaluate your inpainting algorithm on DDPM diffusion with and without class conditioning.\n",
    "\n",
    "Hints:\n",
    "* There are different ways of performing this task but the most straightforward implementation contains a single for-loop similar to the standard reverse-diffusion process. The only difference is that the pixels of the known parts should converge to the known values by using an appropriate distribution to draw samples from.\n",
    "\n",
    "* You may need to use distributions $q(x_{t - 1} | x_t, x_0)$ (for DDPM) or $q_{\\tau}(x_{\\tau_{i -1}} | x_{\\tau_{i}}, x_0)$ (for DDIM), where $x_0$ is a known image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1cbb9",
   "metadata": {
    "deletable": false,
    "id": "a4b1cbb9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7e4e81b9eb7d5a3bb94ef6ebe5c9a55",
     "grade": false,
     "grade_id": "cell-07eb823941c68f14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inpaint(diffusion, model, images, mask_known, labels=None):\n",
    "    \"\"\"Generate samples conditioned on known parts of images.\n",
    "\n",
    "    Args:\n",
    "      diffusion: The descriptor of a diffusion model.\n",
    "      model: A denoising model: model(x, t, labels) outputs a denoised version of input x.\n",
    "      images of shape (batch_size, n_channels, H, W): Conditioning images.\n",
    "      mask_known of shape (batch_size, 1, H, W): BoolTensor which specifies known pixels in images (marked as True).\n",
    "      labels of shape (batch_size,): Classes of images, None for no conditioning on classes.\n",
    "\n",
    "    Returns:\n",
    "      x of shape (batch_size, n_channels, H, W): Generated samples (one sample per input image).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722e6d9",
   "metadata": {
    "id": "c722e6d9",
    "outputId": "97105f4d-52ce-45bf-ce0c-02638f054a48",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This script uses your function to perform conditional generation\n",
    "if not skip_training:\n",
    "    with torch.no_grad():\n",
    "        image, label = trainset[4]  # Select one image from the dataset\n",
    "        images = image[None, 0].tile(120, 1, 1, 1)  # Copy the image to generate multiple samples\n",
    "        images = images.to(device)\n",
    "\n",
    "        labels = torch.cat([torch.arange(10, dtype=torch.int32) for _ in range(12)], dim=0).to(device)\n",
    "        #labels = None # uncomment for unconditional generation\n",
    "        #labels = torch.cat([torch.zeros(10, dtype=torch.int32) + label for _ in range(12)], dim=0).to(device)  # uncomment to generate images of the same class as the masked image\n",
    "        (batch_size, _, H, W) = images.shape\n",
    "\n",
    "        # mask out the bottom part of every image\n",
    "        mask_known = torch.zeros(batch_size, 1, H, W, dtype=torch.bool, device=device)\n",
    "        mask_known[:, :, :H//2, :] = 1\n",
    "        images_known = images * mask_known\n",
    "\n",
    "        samples01 = ((images_known + 1) / 2).clip(0, 1)\n",
    "        print('Conditioning:')\n",
    "        tools.show_images(samples01[:120], cmap='binary', ncol=10)\n",
    "\n",
    "        samples = inpaint(ddim_diffusion, model, images_known, mask_known, labels=labels)\n",
    "        samples01 = ((samples + 1) / 2).clip(0, 1)\n",
    "        tools.show_images(samples01[:120], cmap='binary', ncol=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3fbee8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1f3fbee8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8e1e98d85e12cd073ded58368561f54",
     "grade": true,
     "grade_id": "cell-52c9f4f6db25c28f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "2dd31855-a515-419a-bd23-09df6f23a37d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_fid_score_inpaint(diffusion, model):\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=False)\n",
    "\n",
    "    (images, labels) = next(iter(trainloader))\n",
    "    images = images.to(device)\n",
    "    labels = None\n",
    "    (batch_size, _, H, W) = images.shape\n",
    "\n",
    "    # mask out the bottom part of every image\n",
    "    mask_known = torch.zeros(batch_size, 1, H, W, dtype=torch.bool, device=device)\n",
    "    mask_known[:, :, :H//2, :] = 1\n",
    "    images_known = images * mask_known\n",
    "\n",
    "    if not skip_training:\n",
    "        model.eval()\n",
    "        samples = inpaint(diffusion, model, images_known, mask_known, labels=labels)\n",
    "        torch.save(samples, '1_cond_samples.pth')\n",
    "\n",
    "    else:\n",
    "        samples = torch.load('1_cond_samples.pth', map_location=lambda storage, loc: storage)\n",
    "\n",
    "    # Check conditioning\n",
    "    mse = (samples - images)[mask_known].square().mean().item()\n",
    "    print('MSE:', mse)\n",
    "    assert mse < 1e-5, 'The known pixels should not change.'\n",
    "\n",
    "    fdscore = fd.FDScore.pretrained(imsize=32)\n",
    "    fdscore.to(device)\n",
    "    score = fdscore.calculate(samples)\n",
    "    print('FD score:', score)\n",
    "    assert score < 3.5, 'The FD score should be below 3.5.'\n",
    "    print('Success')\n",
    "\n",
    "test_fid_score_inpaint(diffusion, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d9e65",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "815d9e65",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8a8301525447b2b71e601aafb707020",
     "grade": false,
     "grade_id": "cell-07cb009a4da0e0c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion</b>\n",
    "</div>\n",
    "\n",
    "In this exercise, we trained a diffusion-based generative model and learned how to use the trained model for image in-painting."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
